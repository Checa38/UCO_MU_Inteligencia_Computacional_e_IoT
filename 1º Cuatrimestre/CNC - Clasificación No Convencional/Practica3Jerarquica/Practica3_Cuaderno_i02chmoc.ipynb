{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica 3: Clasificación jerárquica\n",
        "### Carlos Checa Moreno\n",
        "### i02chmoc@uco.es\n",
        "Cuaderno Google Colab: https://colab.research.google.com/drive/1cUB67oeCzo0BzhF9w8lexJTJYU8Zih3m?usp=sharing\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx6j_niWS4EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo: El objetivo de esta práctica es introducir los conceptos de clasificación jerárquica\n",
        "\n",
        "La práctica se puede realizar siguiendo una de las dos opciones siguientes:"
      ],
      "metadata": {
        "id": "cYxj8j5or4A6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPCIÓN 2: Comparación de métodos\n",
        "Seleccione al menos dos algoritmos de los disponibles en la bibliotecas indicadas. Seleccione al menos tres problemas de clasificación jerárquica de los repositorios indicados.\n",
        "Realice las siguientes tareas:\n",
        "1. Aplique los algoritmos seleccionados a los datasets\n",
        "2. Compare los resultados y explique qué conclusiones se podrían obtener"
      ],
      "metadata": {
        "id": "jyDYt05oTZJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalación librería"
      ],
      "metadata": {
        "id": "L8Wo9KYaq7Ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaré la librería [hiclass](https://github.com/scikit-learn-contrib/hiclass) aportada en los apuntes de la asignatura."
      ],
      "metadata": {
        "id": "rbefvr0_rCa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hiclass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qd1p_9Ts03y",
        "outputId": "81ba7e3b-b91f-45fa-aac6-fc987258898f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hiclass\n",
            "  Downloading hiclass-5.0.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from hiclass) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hiclass) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=1.5 in /usr/local/lib/python3.11/dist-packages (from hiclass) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hiclass) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.5->hiclass) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.5->hiclass) (3.5.0)\n",
            "Downloading hiclass-5.0.3-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hiclass\n",
            "Successfully installed hiclass-5.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from hiclass import LocalClassifierPerNode, LocalClassifierPerParentNode\n",
        "from hiclass.metrics import f1, precision, recall"
      ],
      "metadata": {
        "id": "Hp2mc33iQTmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descarga dataset"
      ],
      "metadata": {
        "id": "bmfPNNT6rSWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O complaints.csv.zip 'https://files.consumerfinance.gov/ccdb/complaints.csv.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyl3JU9X-qiY",
        "outputId": "c3c8e091-1cb3-4172-cb02-fa7103e34ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-28 15:52:20--  https://files.consumerfinance.gov/ccdb/complaints.csv.zip\n",
            "Resolving files.consumerfinance.gov (files.consumerfinance.gov)... 18.160.46.26, 18.160.46.121, 18.160.46.39, ...\n",
            "Connecting to files.consumerfinance.gov (files.consumerfinance.gov)|18.160.46.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1047695442 (999M) [binary/octet-stream]\n",
            "Saving to: ‘complaints.csv.zip’\n",
            "\n",
            "complaints.csv.zip  100%[===================>] 999.16M   128MB/s    in 9.6s    \n",
            "\n",
            "2025-02-28 15:52:29 (105 MB/s) - ‘complaints.csv.zip’ saved [1047695442/1047695442]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocesado de Datos"
      ],
      "metadata": {
        "id": "1xqkMRZsUfWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se carga el dataset, se eliminan valores nulos y se toma una muestra del 1%.\n",
        "\n",
        "He decidido quedarme con una fracción del dataset para reducir el tiempo de ejecución ya que es un dataset considerablemente grande y los algoritmos que se utilizarán requieren un gran cantidad de memoria."
      ],
      "metadata": {
        "id": "qOAztBqHUoIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''------------ CARGA DEL DATASET ---------------'''\n",
        "data = pd.read_csv(\n",
        "    'complaints.csv.zip',\n",
        "    compression='zip',\n",
        "    header=0,\n",
        "    sep=',',\n",
        "    usecols=[\"Consumer complaint narrative\", \"Product\", \"Sub-product\"]\n",
        ")\n",
        "data.dropna(inplace=True)\n",
        "data = data.sample(frac=0.1, random_state=42)\n",
        "\n",
        "X = data[\"Consumer complaint narrative\"].to_numpy()\n",
        "y = data[[\"Product\", \"Sub-product\"]].to_numpy()"
      ],
      "metadata": {
        "id": "Ma89SDnE-9NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### División del Conjuto de Datos"
      ],
      "metadata": {
        "id": "9nF5EHcDVZTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divido los datos de entrenamiento en 70% entrenamienot y 30% test.\n"
      ],
      "metadata": {
        "id": "qBqGv2psZ5Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''------------ DIVISIÓN DEL CONJUNTO DE DATOS ---------------'''\n",
        "# Dividir en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "2bLhaB81VXt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de Modelos"
      ],
      "metadata": {
        "id": "vacpst0IVevU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaré Regresión Logística como clasificador base, con un número alto de iteraciones para asegurar convergencia.\n",
        "\n",
        "Como modelos a comparar he seleccionado: **LCPN** (Local Classifier Per Node) que entrena un clasificador por cada nodo de la jerarquía y **LCPPN** (Local Classifier Per Parent Node), el cual entrena un clasificador por cada nodo padre en la jerarquía."
      ],
      "metadata": {
        "id": "24pWWXUoaIDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''------------ DEFINICIÓN DE LOS MODELOS ---------------'''\n",
        "# Se usa un clasificador base de Regresión Logística para ambos modelos.\n",
        "base_classifier = LogisticRegression(random_state=42, max_iter=10000, n_jobs=1)\n",
        "\n",
        "# Se definen los dos modelos de clasificación jerárquica a evaluar.\n",
        "models = {\n",
        "    \"LCPN\": LocalClassifierPerNode(local_classifier=base_classifier, verbose=0, n_jobs=1),\n",
        "    \"LCPPN\": LocalClassifierPerParentNode(local_classifier=base_classifier, verbose=0, n_jobs=1)\n",
        "}"
      ],
      "metadata": {
        "id": "LvMvK67x--xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "761FaEDGV-Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''------------ ENTRENAMIENTO Y EVALUACIÓN DE LOS MODELOS ---------------'''\n",
        "# Evaluar cada modelo\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Entrenando {name}...\")\n",
        "    pipeline = Pipeline([\n",
        "        ('count', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('model', model),\n",
        "    ])\n",
        "\n",
        "    start_time = time.time()\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    predictions = pipeline.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Tiempo de entrenamiento\": training_time,\n",
        "        \"F1-score\": f1(y_test, predictions),\n",
        "        \"Precisión\": precision(y_test, predictions),\n",
        "        \"Recall\": recall(y_test, predictions)\n",
        "    }"
      ],
      "metadata": {
        "id": "jkiNPIC__ADP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7a9a77-7245-472d-8ae3-74e7943f3ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando LCPN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando LCPPN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación"
      ],
      "metadata": {
        "id": "Rv6vWVYmWC4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar resultados\n",
        "for model, metrics in results.items():\n",
        "    print(f\"Resultados de {model}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Qo1iA8ZwauHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd87e27-dc59-4f60-d8ab-6a1879f685a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de LCPN:\n",
            "Tiempo de entrenamiento: 250.35141396522522\n",
            "F1-score: 0.7519215675661046\n",
            "Precisión: 0.7519215675661046\n",
            "Recall: 0.7519215675661046\n",
            "\n",
            "\n",
            "Resultados de LCPPN:\n",
            "Tiempo de entrenamiento: 451.2287962436676\n",
            "F1-score: 0.759465750087959\n",
            "Precisión: 0.759465750087959\n",
            "Recall: 0.759465750087959\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretación resultados"
      ],
      "metadata": {
        "id": "_hEdJyxtqo66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "        <tr>\n",
        "            <th>Modelo</th>\n",
        "            <th>Tiempo de Entrenamiento</th>\n",
        "            <th>F1-score</th>\n",
        "            <th>Precisión</th>\n",
        "            <th>Recall</th>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>LCPN</td>\n",
        "            <td>250.35 s</td>\n",
        "            <td>0.7519</td>\n",
        "            <td>0.7519</td>\n",
        "            <td>0.7519</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>LCPPN</td>\n",
        "            <td>451.23 s</td>\n",
        "            <td>0.7595</td>\n",
        "            <td>0.7595</td>\n",
        "            <td>0.7595</td>\n",
        "        </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "a1Ej6EeUqyrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizando los resultados obtenidos:\n",
        "\n",
        "*  El modelo **LCPN** ha requerido 250,35 segundos para entrenarse, obteniendo métricas de rendimiento equilibradas con F1-score, Precisión y Recall de 0.7519. Esto indica que el modelo logra una clasificación adecuada, aunque con margen de mejora.\n",
        "\n",
        "*  El modelo **LCPPN**, por otro lado, ha necesitado 451.23 segundos para entrenarse, es decir, casi el doble de tiempo. Aunque ha logrado un desempeño ligeramente superior, con un F1-score, Precisión y Recall de 0.7595.\n",
        "\n",
        "El aumento en el tiempo de entrenamiento del modelo LCPPN se justifica por la estrategia que utiliza para entrenar un clasificador por cada nodo padre en la jerarquía. A cambio, ofrece una ligera mejora en las métricas de rendimiento. Sin embargo, no considero que el aumento del desempeño sea suficiente para amortizar el aumento de tiempo de cómputo.\n",
        "\n",
        "Si el tiempo de entrenamiento no es una restricción crítica, LCPPN podría ser una mejor opción. Sin embargo, si se busca un balance entre eficiencia y precisión, LCPN sería una mejor para este dataset."
      ],
      "metadata": {
        "id": "q0DotnAEpG3F"
      }
    }
  ]
}